This lab demonstrates the feature engineering process for building a regression model using bike rental demand prediction as an example.
In machine learning predictions, effective feature engineering will lead to a more accurate model. 
We will use the Bike Rental UCI dataset as the input raw data for this experiment.
The dataset contains 17,379 rows and 17 columns, each row representing the number of bike rentals within a specific hour of a day in the years 2011 or 2012.
Weather conditions (such as temperature, humidity, and wind speed) were included in this raw feature set, and the dates were categorized as holiday vs. weekday etc.

The field to predict is cnt which contains a count value ranging from 1 to 977, representing the number of bike rentals within a specific hour.
Our main goal is to construct effective features in the training data, so we build two models using the same algorithm, but with two different datasets.
Using the Split Data module in the visual designer, we split the input data in such a way that the training data contains records for the year 2011, 
and the testing data, records for 2012. Both datasets have the same raw data at the origin, but we added different additional features to each training set:

Set A = weather + holiday + weekday + weekend features for the predicted day
Set B = number of bikes that were rented in each of the previous 12 hours
We are building two training datasets by combining the feature set as follows:

Training set 1: feature set A only
Training set 2: feature sets A+B
For the model, we are using regression because the number of rentals (the label column) contains continuos real numbers. As the algorithm for the experiment,
we will be using the Boosted Decision Tree Regression.
